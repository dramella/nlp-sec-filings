{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Libraries](#toc1_)    \n",
    "- [Loading 10 text filings per type](#toc2_)    \n",
    "- [Preprocessing: a pipeline example](#toc3_)    \n",
    "- [Dictionary approach: Loughran-McDonald, VADER](#toc4_)    \n",
    "  - [Loughran-McDonald](#toc4_1_)    \n",
    "  - [Vader](#toc4_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Debora/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "os.chdir(os.environ.get('PROJECT_PATH'))\n",
    "from secnlp.ml_logic import data as d\n",
    "from secnlp.ml_logic import parsing as p\n",
    "from secnlp.ml_logic import preprocessing as pre\n",
    "import secnlp.ml_logic.parsing\n",
    "from secnlp import utils as u\n",
    "from secnlp.params import *\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Loading 10 text filings per type](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load whole filings table\n",
    "df = u.read_data_from_bq(credentials = SERVICE_ACCOUNT, gcp_project = PROJECT, bq_dataset = DATASET_ID, table = FILINGS_10KQ_TABLE_ID)\n",
    "df['date_filed'] = pd.to_datetime(df['date_filed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to locate Item 7\n",
      "Unable to locate Item 7\n",
      "Unable to locate Item 7\n"
     ]
    }
   ],
   "source": [
    "# sample 10 \"Management & Discussion Analysis\" sections of 10-K filings\n",
    "importlib.reload(secnlp.ml_logic.parsing)\n",
    "filing_sample_10k = df[(df['date_filed'].dt.year == 2023) & (df['form_type'] == '10-K')].sample(10)\n",
    "filing_sample_10k['raw_filing'] = filing_sample_10k['file_name'].apply(lambda url: d.fetch_text_from_url(url, agent = AGENT))\n",
    "filing_sample_10k['mda'] = filing_sample_10k['raw_filing'].apply(lambda x: p.parse_10k_filing_items(x, item = '7'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to locate Item 2\n",
      "Unable to locate Item 2\n",
      "Unable to locate Item 2\n"
     ]
    }
   ],
   "source": [
    "# sample 10 \"Management & Discussion Analysis\" sections of 10-Q filings\n",
    "filing_sample_10q = df[(df['date_filed'].dt.year == 2023) & (df['form_type'] == '10-Q')].sample(10)\n",
    "filing_sample_10q['raw_filing'] = filing_sample_10q['file_name'].apply(lambda url: d.fetch_text_from_url(url, agent = AGENT))\n",
    "filing_sample_10q['mda'] = filing_sample_10q['raw_filing'].apply(lambda x: p.parse_10q_filing_items(x, item = '2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Preprocessing: a pipeline example](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "text = p.cleaning(filing_sample_10k['mda'].iloc[1])\n",
    "# Tokenizing\n",
    "tokenized = word_tokenize(text)\n",
    "# Lemmatizing\n",
    "verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in tokenized]\n",
    "noun_verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in verb_lemmatized]\n",
    "# Vectorizing\n",
    "vectorizer = CountVectorizer(stop_words=None,ngram_range = (2,2))\n",
    "X_bow = vectorizer.fit_transform([\" \".join(noun_verb_lemmatized)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cleaning',\n",
      "                 FunctionTransformer(func=<function cleaning at 0x142e6cb80>)),\n",
      "                ('vectorizing',\n",
      "                 CountVectorizer(ngram_range=(2, 2),\n",
      "                                 tokenizer=<secnlp.ml_logic.preprocessing.LemmaTokenizer object at 0x147a8d690>))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Debora/.pyenv/versions/3.10.6/envs/nlpsec/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>114</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  501  502  503  504  \\\n",
       "0    8   68  114   46   14    4    6   11   14    5  ...    8   45    2   14   \n",
       "\n",
       "   505  506  507  508  509  510  \n",
       "0    2    2    6    6    6   25  \n",
       "\n",
       "[1 rows x 511 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply full preprocessing pipeline to the data\n",
    "print(pre.pipeline_without_stop_words)\n",
    "X_bow = pre.pipeline_without_stop_words.fit_transform([filing_sample_10k['mda'].iloc[1]])\n",
    "display(pd.DataFrame(X_bow.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Dictionary approach: Loughran-McDonald, VADER](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Loughran-McDonald](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Word_Proportion</th>\n",
       "      <th>Average_Proportion</th>\n",
       "      <th>Std_Dev</th>\n",
       "      <th>Doc_Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WICKING</td>\n",
       "      <td>85138</td>\n",
       "      <td>613</td>\n",
       "      <td>2.684178e-08</td>\n",
       "      <td>1.801378e-08</td>\n",
       "      <td>1.877609e-06</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISALLOCATION</td>\n",
       "      <td>46609</td>\n",
       "      <td>1003</td>\n",
       "      <td>4.391894e-08</td>\n",
       "      <td>5.292175e-08</td>\n",
       "      <td>4.437696e-06</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIMESCALES</td>\n",
       "      <td>77593</td>\n",
       "      <td>1003</td>\n",
       "      <td>4.391894e-08</td>\n",
       "      <td>2.024676e-08</td>\n",
       "      <td>1.712593e-06</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNSEASONAL</td>\n",
       "      <td>81884</td>\n",
       "      <td>404</td>\n",
       "      <td>1.769018e-08</td>\n",
       "      <td>1.899141e-08</td>\n",
       "      <td>1.960269e-06</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANSOMWARE</td>\n",
       "      <td>60772</td>\n",
       "      <td>7271</td>\n",
       "      <td>3.183794e-07</td>\n",
       "      <td>1.577411e-07</td>\n",
       "      <td>4.265672e-06</td>\n",
       "      <td>5231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CARETAKING</td>\n",
       "      <td>10661</td>\n",
       "      <td>571</td>\n",
       "      <td>2.500270e-08</td>\n",
       "      <td>2.665711e-08</td>\n",
       "      <td>3.132363e-06</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UNDERSUBSCRIPTION</td>\n",
       "      <td>80820</td>\n",
       "      <td>571</td>\n",
       "      <td>2.500270e-08</td>\n",
       "      <td>8.405338e-09</td>\n",
       "      <td>1.357159e-06</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CRYPTOCURRENCY</td>\n",
       "      <td>17473</td>\n",
       "      <td>13673</td>\n",
       "      <td>5.987075e-07</td>\n",
       "      <td>5.765699e-07</td>\n",
       "      <td>3.263651e-05</td>\n",
       "      <td>1229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STRATEGIZING</td>\n",
       "      <td>73555</td>\n",
       "      <td>557</td>\n",
       "      <td>2.438968e-08</td>\n",
       "      <td>3.381807e-08</td>\n",
       "      <td>2.284727e-06</td>\n",
       "      <td>454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>REPROPOSED</td>\n",
       "      <td>63732</td>\n",
       "      <td>348</td>\n",
       "      <td>1.523808e-08</td>\n",
       "      <td>6.361126e-09</td>\n",
       "      <td>6.235705e-07</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10K_2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Seq_num  Word_Count  Word_Proportion  \\\n",
       "0            WICKING    85138         613     2.684178e-08   \n",
       "1      MISALLOCATION    46609        1003     4.391894e-08   \n",
       "2         TIMESCALES    77593        1003     4.391894e-08   \n",
       "3         UNSEASONAL    81884         404     1.769018e-08   \n",
       "4         RANSOMWARE    60772        7271     3.183794e-07   \n",
       "5         CARETAKING    10661         571     2.500270e-08   \n",
       "6  UNDERSUBSCRIPTION    80820         571     2.500270e-08   \n",
       "7     CRYPTOCURRENCY    17473       13673     5.987075e-07   \n",
       "8       STRATEGIZING    73555         557     2.438968e-08   \n",
       "9         REPROPOSED    63732         348     1.523808e-08   \n",
       "\n",
       "   Average_Proportion       Std_Dev  Doc_Count  Negative  Positive  \\\n",
       "0        1.801378e-08  1.877609e-06        306         0         0   \n",
       "1        5.292175e-08  4.437696e-06        628         0         0   \n",
       "2        2.024676e-08  1.712593e-06        459         0         0   \n",
       "3        1.899141e-08  1.960269e-06        332         0         0   \n",
       "4        1.577411e-07  4.265672e-06       5231         0         0   \n",
       "5        2.665711e-08  3.132363e-06        239         0         0   \n",
       "6        8.405338e-09  1.357159e-06         88         0         0   \n",
       "7        5.765699e-07  3.263651e-05       1229         0         0   \n",
       "8        3.381807e-08  2.284727e-06        454         0         0   \n",
       "9        6.361126e-09  6.235705e-07        209         0         0   \n",
       "\n",
       "   Uncertainty  Litigious  Strong_Modal  Weak_Modal  Constraining  Syllables  \\\n",
       "0            0          0             0           0             0          0   \n",
       "1            0          0             0           0             0          0   \n",
       "2            0          0             0           0             0          0   \n",
       "3            0          0             0           0             0          0   \n",
       "4            0          0             0           0             0          0   \n",
       "5            0          0             0           0             0          0   \n",
       "6            0          0             0           0             0          0   \n",
       "7            0          0             0           0             0          0   \n",
       "8            0          0             0           0             0          0   \n",
       "9            0          0             0           0             0          0   \n",
       "\n",
       "     Source  \n",
       "0  10K_2014  \n",
       "1  10K_2018  \n",
       "2  10K_2014  \n",
       "3  10K_2014  \n",
       "4  10K_2018  \n",
       "5  10K_2014  \n",
       "6  10K_2018  \n",
       "7  10K_2018  \n",
       "8  10K_2014  \n",
       "9  10K_2014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loughran_mcdonald = u.read_data_from_bq(credentials = SERVICE_ACCOUNT, gcp_project = PROJECT, bq_dataset = DATASET_ID, table = LOUGHRAN_MCDONALD_TABLE_ID)\n",
    "display(loughran_mcdonald.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative\n",
       "0        84176\n",
       "2009      2305\n",
       "2014        26\n",
       "2011        13\n",
       "-2020       10\n",
       "2012         1\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loughran_mcdonald['Negative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = loughran_mcdonald[loughran_mcdonald['Positive'] > 0]['Word'].values\n",
    "neg_words = loughran_mcdonald[loughran_mcdonald['Negative'] > 0]['Word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words Count: 176, Negative Words Count: 643, Sentiment Score:0.3\n"
     ]
    }
   ],
   "source": [
    "# Cleaning\n",
    "text = p.cleaning(filing_sample_10k['mda'].iloc[1])\n",
    "# Tokenizing\n",
    "tokenized = word_tokenize(text)\n",
    "# Stop Words\n",
    "stop_words = stopwords.words('english')\n",
    "# Lemmatizing\n",
    "verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in tokenized if word not in stop_words]\n",
    "noun_verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in verb_lemmatized if word not in stop_words]\n",
    "# Calculating sentiment score\n",
    "num_pos = [i for i in noun_verb_lemmatized if i.upper() in pos_words]\n",
    "num_neg = [i for i in noun_verb_lemmatized if i.upper() in neg_words]\n",
    "sentiment_score_ld = round(len(num_pos) / (len(num_neg)+1), 2)\n",
    "print(f\"Positive Words Count: {len(num_pos)}, Negative Words Count: {len(num_neg)}, Sentiment Score:{sentiment_score_ld}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[Vader](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.042, 'neu': 0.857, 'pos': 0.101, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment_score_vader = sent_analyzer.polarity_scores(filing_sample_10k['mda'].iloc[1])\n",
    "print(sentiment_score_vader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
